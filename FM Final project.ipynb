{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpmul\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:37: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Test PyTorch installation\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "class MagicCards(pl.LightningDataModule):\n",
    "    \"\"\" A datamodule for the RNN. \"\"\"\n",
    "    def __init__(self, dict_size=77, batch_size=128, loc=\"./data/minitrain.txt\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dict_size = dict_size\n",
    "        self.batch_size = batch_size\n",
    "        self.example_length = None\n",
    "        self.loc = loc\n",
    "\n",
    "        # preprocess training data\n",
    "        self.tok = Tokenizer(num_words=dict_size, char_level=True, filters=\"\", lower=False,)\n",
    "\n",
    "    def load_data(self, location):\n",
    "        with open(location, 'rt') as f:\n",
    "            return f.read()\n",
    "    \n",
    "    def make_dataset(self, documents, tok=None):\n",
    "        # tokenize\n",
    "        sequences = self.tok.texts_to_sequences(documents)\n",
    "        \n",
    "        x = sequences\n",
    "        y = [sequence[1:] for sequence in sequences]\n",
    "        #Now we pad. We post pad here because we will be generating sequentially\n",
    "        #and do not want to get squeezed\n",
    "        x = sequence.pad_sequences(x, padding=\"post\")\n",
    "        self.example_length = len(x[0])\n",
    "        y = sequence.pad_sequences(y, padding=\"post\", maxlen=self.example_length)\n",
    "        \n",
    "        \n",
    "        # make torch arrays.\n",
    "        x = torch.from_numpy(x).to(torch.int64)\n",
    "        y = torch.from_numpy(y).to(torch.int64)\n",
    "        \n",
    "        return TensorDataset(x, y)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # load data\n",
    "        train_seqs = self.load_data(self.loc).split(\"\\n\\n\")\n",
    "        \n",
    "        # fit tokenizer\n",
    "        self.tok.fit_on_texts(train_seqs)\n",
    "        \n",
    "        # make datasets\n",
    "        self.train = self.make_dataset(train_seqs)\n",
    "        self.test = self.train\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True,\n",
    "                          num_workers=mp.cpu_count() // 4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size, shuffle=False,\n",
    "                          num_workers=mp.cpu_count() // 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_onehot(inp, dict_length=None):\n",
    "    inp = np.array(inp)\n",
    "    if dict_length == None:\n",
    "        dict_length = inp.max+1\n",
    "    \n",
    "    one_hot = np.zeros((inp.size, dict_length))\n",
    "    one_hot[np.arange(inp.size), inp] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "class RNN(pl.LightningModule):\n",
    "    \"\"\" Baseline RNN classifier \"\"\"\n",
    "\n",
    "    def __init__(self, dict_size=77, example_length=660, lstm_layers=1, dropout=0.5, rnn_width=256):\n",
    "        \"\"\"\n",
    "        initialize RNN model\n",
    "        :param embedding_length: size of word embedding\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # To complete this function, you will need PyTorch's Embedding, LSTM and linear layers.\n",
    "        \n",
    "        # The embedding layer simply creates a dictionary between words in your vocabulary and their vector \n",
    "        # representations. Therefore, each word has a unique representation.\n",
    "        # For instance, say your input x is encoded as [1, 5, 9] and embedding_dim = 32 (see documentation for \n",
    "        # arguments to this layer), then after passing through the embedding layer the output will be \n",
    "        # of shape 3x32\n",
    "        \n",
    "        # Documentation for LSTM layer in :\n",
    "        #     https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM\n",
    "        \n",
    "        # Note there are multiple ways to define your model, \n",
    "        # we suggest adding individual layers here, but any method is fine.\n",
    "        \n",
    "        # As an example, you could define a linear layer with n inputs and m outputs like so:\n",
    "        # self.linear = nn.Linear(n, m)\n",
    "        \n",
    "        # Similarly, define the three layers needed for your model\n",
    "        \n",
    "        # TODO: build model by defining individual layers in the network\n",
    "            \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.dict_size = dict_size\n",
    "        self.num_layers = lstm_layers\n",
    "        self.lstm_size = rnn_width\n",
    "        self.emb_layer = nn.Embedding(dict_size, rnn_width)\n",
    "        self.lstm_layer = nn.LSTM(rnn_width, rnn_width,\n",
    "                                  batch_first=True,\n",
    "                                  num_layers=lstm_layers,\n",
    "                                  dropout=dropout)\n",
    "        self.lin_layer = nn.Linear(rnn_width, dict_size)\n",
    "        \n",
    "        self.save_hyperparameters('dict_size', 'rnn_width')\n",
    "\n",
    "        self.example_input_array = torch.zeros([1, example_length], dtype=torch.int64)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        Pytorch allows you to stack layers on top of each other very easily.\n",
    "        \n",
    "        For example, if we have layers self.layer1 and self.layer2 acting on input x, we can do\n",
    "        out_1 = self.layer1(x)\n",
    "        out_2 = self.layer2(out_1)\n",
    "        This would constitute a forward pass for the above hypothetical network.\n",
    "        \n",
    "        Your job in this function is to propagate the input x through the network you defined in __init__()\n",
    "        \n",
    "        TODO:\n",
    "        1. Pass input though embedding layer\n",
    "        2. Propagate output of previous step through LSTM\n",
    "        3. Pass final output of LSTM through linear layer\n",
    "        4. Apply Sigmoid activation (torch.sigmoid()) to output of step 3 to obtain probabilities\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        embed = self.emb_layer(x)\n",
    "        lstm_out, _ = self.lstm_layer(embed)\n",
    "        lin_out = self.lin_layer(lstm_out)\n",
    "        return lin_out\n",
    "\n",
    "    def accuracy(self, y_hat, y):\n",
    "        return (y == y_hat).to(torch.float32).mean()\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\" Perfom a training step. \n",
    "        \n",
    "        This is just one step on one batch during training (no looping required) \n",
    "        \n",
    "        TODO:\n",
    "            - forward pass on data in batch\n",
    "            - compute training loss (use PyTorch's F.binary_cross_entropy since this is binary classification)\n",
    "            - Compute training accuracy (using the self.accuracy function)\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        x,y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        m = nn.CrossEntropyLoss()\n",
    "        predicts = torch.argmax(F.softmax(y_hat), dim=2)\n",
    "        loss = m(y_hat.view(-1,self.dict_size), y.view(-1))\n",
    "        # We implemented logging for you. \n",
    "        result = pl.TrainResult(loss)\n",
    "        \n",
    "        acc = self.accuracy(predicts.view(-1), y.view(-1))\n",
    "        result.log('train_loss', loss, prog_bar=True)\n",
    "        result.log('train_accuracy', acc, prog_bar=True)\n",
    "        #print(result)\n",
    "        return result\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\" Perfom a test step \n",
    "            hint: your code should be the same as your train step\n",
    "        \n",
    "        TODO:\n",
    "            - forward pass on data in batch\n",
    "            - compute test loss \n",
    "            - Compute test accuracy  \n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        x,y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        m = nn.CrossEntropyLoss()\n",
    "        predicts = torch.argmax(y_hat, dim=2)\n",
    "        \n",
    "        loss = m(y_hat.view(-1,self.dict_size), y.view(-1))\n",
    "        # We implemented logging for you. \n",
    "        result = pl.EvalResult(loss)\n",
    "        acc = self.accuracy(predicts.view(-1), y.view(-1))\n",
    "        result.log('test_loss', loss, prog_bar=True)\n",
    "        result.log('test_accuracy', acc, prog_bar=True)\n",
    "        #print(result)\n",
    "        return result\n",
    "    \n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type      | Params | In sizes      | Out sizes                                  \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "0 | emb_layer  | Embedding | 19 K   | [1, 660]      | [1, 660, 256]                              \n",
      "1 | lstm_layer | LSTM      | 526 K  | [1, 660, 256] | [[1, 660, 256], [[1, 1, 256], [1, 1, 256]]]\n",
      "2 | lin_layer  | Linear    | 19 K   | [1, 660, 256] | [1, 660, 77]                               \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf879299b7549a4aa71ab95d5c5851e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpmul\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:106: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'logs\\\\rnn\\\\version_101\\\\metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-f7bbb7939eee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_file_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#print(results)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#print('Accuracy for LSTM: ', results['test_acc'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-f7bbb7939eee>\u001b[0m in \u001b[0;36mrun_rnn\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmagic_cards_dm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_file_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\states.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentering\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;31m# The INTERRUPTED state can be set inside the run function. To indicate that run was interrupted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m   1071\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGPUBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\accelerators\\gpu_backend.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;31m# CORE TRAINING LOOP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 \u001b[1;31m# RUN TNG EPOCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[1;31m# -----------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;31m# SAVE LOGGERS (ie: Tensorboard, etc...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m             \u001b[1;31m# -----------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_loggers_in_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;31m# -----------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36msave_loggers_in_training_loop\u001b[1;34m(self, batch_idx)\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshould_save_log\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_dev_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_global_zero\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrank_zero_only\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\loggers\\csv_logs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mrank_zero_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pytorch_lightning\\loggers\\csv_logs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mmetrics_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'logs\\\\rnn\\\\version_101\\\\metrics.csv'"
     ]
    }
   ],
   "source": [
    "magic_cards_dm = MagicCards()\n",
    "\n",
    "def run_rnn(**kwargs):\n",
    "    # helper function for running RNN.\n",
    "    logger = CSVLogger(\"logs\", name=\"rnn\")\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=int(torch.cuda.is_available()),\n",
    "        logger=logger,\n",
    "        min_epochs=5,\n",
    "        max_epochs=100,\n",
    "        row_log_interval=1,\n",
    "        log_save_interval=1,\n",
    "        deterministic=True\n",
    "    )\n",
    "    \n",
    "    model = RNN(**kwargs)\n",
    "    \n",
    "    trainer.fit(model, datamodule=magic_cards_dm)\n",
    "    results = trainer.test(verbose=True)\n",
    "    return logger.experiment.metrics_file_path\n",
    "\n",
    "metrics = run_rnn()\n",
    "#print(results)\n",
    "#print('Accuracy for LSTM: ', results['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.5551e-01,  5.5576e-01,  8.2455e-01,  8.0354e-01,  1.0944e+00,\n",
      "         6.4976e-01,  2.6734e-01,  5.8669e-01,  6.7656e-01,  1.5497e-01,\n",
      "         4.0713e-01,  3.8916e-01,  1.6793e-01,  4.0804e-03,  2.2180e-01,\n",
      "         2.0296e-02,  2.2211e-01,  8.7089e-02, -1.2386e-01, -6.3576e-02,\n",
      "        -9.8702e-02,  3.4822e-02, -3.4568e-01, -4.2177e-02, -1.9252e-01,\n",
      "        -4.4906e-01, -4.2355e-01, -1.9206e-04, -2.7402e-01, -2.3651e-01,\n",
      "        -1.9048e-01, -5.2799e-01, -1.0828e-01, -5.1150e-01, -1.9999e-01,\n",
      "        -2.7133e-01, -6.5738e-02, -3.6411e-01, -3.0143e-01, -1.7757e-01,\n",
      "        -2.4363e-01, -5.1550e-01, -7.8627e-01, -4.5757e-01, -5.8343e-01,\n",
      "        -3.4619e-01, -3.9465e-01, -3.2228e-01, -3.1348e-01, -3.5865e-01,\n",
      "        -7.7745e-01, -5.4865e-01, -4.1701e-01, -5.4899e-01, -2.7251e-01,\n",
      "        -4.3039e-01, -3.4012e-01, -3.5533e-01, -4.9029e-01, -4.8600e-01,\n",
      "        -3.6669e-01, -4.6858e-01, -2.4954e-01, -3.7135e-01, -5.1150e-01,\n",
      "        -3.2633e-01, -6.3735e-02, -2.7015e-01, -6.3274e-01, -5.2462e-01,\n",
      "        -3.3482e-01, -4.5849e-01, -5.5249e-01, -6.8447e-01, -5.3456e-01,\n",
      "        -5.1591e-01, -4.3633e-01], grad_fn=<SelectBackward>)\n",
      "57\n",
      "[ 6 28 10 57]\n",
      "tensor([ 0.7624,  0.4797,  0.8792,  0.5993,  0.7260,  0.5111,  0.2099,  0.3796,\n",
      "         0.5105,  0.2041,  0.2031,  0.4266,  0.0462,  0.0387,  0.0877, -0.0621,\n",
      "         0.0699, -0.0772, -0.1603, -0.0834, -0.0878,  0.0386, -0.2240, -0.2466,\n",
      "        -0.2234, -0.3107, -0.3274, -0.1790, -0.2428, -0.3000, -0.0739, -0.4627,\n",
      "        -0.2733, -0.3571, -0.2259, -0.2729, -0.1735, -0.4116, -0.0895, -0.2445,\n",
      "        -0.2440, -0.3525, -0.6343, -0.4037, -0.5660, -0.3782, -0.5607, -0.3414,\n",
      "        -0.3050, -0.3359, -0.5873, -0.4602, -0.4177, -0.4968, -0.3653, -0.3865,\n",
      "        -0.3105, -0.3270, -0.4525, -0.5386, -0.5871, -0.4221, -0.2103, -0.3238,\n",
      "        -0.4730, -0.3439, -0.0452, -0.2616, -0.4762, -0.4144, -0.3567, -0.5363,\n",
      "        -0.4556, -0.6358, -0.4203, -0.4141, -0.4562], grad_fn=<SelectBackward>)\n",
      "11\n",
      "[ 6 28 10 57 11]\n",
      "tensor([ 0.8291,  0.9947,  1.2584,  0.7768,  1.1346,  0.8468,  0.3361,  0.9990,\n",
      "         0.5874,  0.2756,  0.3160,  0.4085,  0.4452,  0.1852,  0.4183, -0.0048,\n",
      "         0.1057,  0.0166, -0.1883,  0.1542,  0.0384, -0.0830, -0.5065, -0.1680,\n",
      "        -0.4112, -0.5686, -0.6049, -0.2679, -0.5191, -0.3848, -0.3196, -0.6683,\n",
      "        -0.4246, -0.6582, -0.4388, -0.6289, -0.3648, -0.4057, -0.3621, -0.4991,\n",
      "        -0.4093, -0.5874, -0.7925, -0.6495, -0.7985, -0.5702, -0.6681, -0.4969,\n",
      "        -0.6348, -0.5652, -0.7210, -0.6328, -0.5745, -0.7486, -0.4259, -0.4752,\n",
      "        -0.5574, -0.5881, -0.5739, -0.4898, -0.7238, -0.7058, -0.3676, -0.6105,\n",
      "        -0.6830, -0.4973, -0.4014, -0.3673, -0.7299, -0.6377, -0.4528, -0.6975,\n",
      "        -0.6900, -0.8629, -0.5442, -0.6241, -0.6830], grad_fn=<SelectBackward>)\n",
      "46\n",
      "[ 6 28 10 57 11 46]\n",
      "tensor([ 0.8270,  1.1023,  0.9745,  0.5280,  0.9334,  0.8019,  0.4550,  0.7965,\n",
      "         0.3275,  0.1900,  0.2978,  0.2411,  0.3140,  0.1199,  0.2612, -0.0429,\n",
      "         0.1612, -0.0153, -0.1615, -0.0592,  0.0037, -0.0616, -0.5137, -0.0014,\n",
      "        -0.4090, -0.4353, -0.6394, -0.3368, -0.5108, -0.4586, -0.3867, -0.5824,\n",
      "        -0.4518, -0.5800, -0.3156, -0.5222, -0.3715, -0.4943, -0.4213, -0.5474,\n",
      "        -0.3455, -0.4226, -0.6730, -0.6246, -0.6997, -0.5587, -0.3616, -0.4522,\n",
      "        -0.5628, -0.5711, -0.7222, -0.4460, -0.4007, -0.8548, -0.4207, -0.3923,\n",
      "        -0.4525, -0.5314, -0.5522, -0.5273, -0.7561, -0.5948, -0.4824, -0.5854,\n",
      "        -0.7964, -0.6513, -0.4769, -0.4437, -0.7000, -0.6066, -0.3139, -0.7284,\n",
      "        -0.6319, -0.8390, -0.6598, -0.5738, -0.5288], grad_fn=<SelectBackward>)\n",
      "42\n",
      "[ 6 28 10 57 11 46 42]\n",
      "tensor([ 0.8104,  0.9344,  0.8967,  0.5742,  0.6668,  0.5627,  0.3932,  0.5874,\n",
      "         0.0966,  0.4714,  0.2236,  0.1534,  0.2732,  0.0273,  0.1868, -0.0866,\n",
      "        -0.0093,  0.0428, -0.0415, -0.0237, -0.0315, -0.0730, -0.4540, -0.0341,\n",
      "        -0.3920, -0.2859, -0.5893, -0.4204, -0.5033, -0.5897, -0.3748, -0.4146,\n",
      "        -0.4198, -0.4887, -0.1992, -0.7006, -0.2540, -0.4245, -0.2983, -0.5334,\n",
      "        -0.3362, -0.2924, -0.2059, -0.4934, -0.6387, -0.4998, -0.3598, -0.5185,\n",
      "        -0.5425, -0.3887, -0.6551, -0.5340, -0.3685, -0.6931, -0.2243, -0.4825,\n",
      "        -0.4598, -0.6305, -0.6669, -0.4623, -0.6848, -0.5289, -0.5437, -0.7336,\n",
      "        -0.5345, -0.6112, -0.4691, -0.6350, -0.6176, -0.6485, -0.4361, -0.4887,\n",
      "        -0.7955, -0.7020, -0.7235, -0.6660, -0.5317], grad_fn=<SelectBackward>)\n",
      "3\n",
      "[ 6 28 10 57 11 46 42  3]\n",
      "tensor([ 1.5156,  1.0962,  1.1966,  0.6441,  1.5980,  1.5168,  0.2754,  1.1811,\n",
      "         0.1055,  0.0143,  0.4630,  0.2131,  0.1761,  0.2063,  0.3667,  0.0331,\n",
      "         0.0132, -0.0704, -0.1914, -0.0713, -0.0064, -0.2095, -0.9274, -0.2289,\n",
      "        -0.7284, -0.8127, -0.7475, -0.5029, -0.8066, -0.6713, -0.8025, -0.7014,\n",
      "        -1.0070, -0.9582, -0.4604, -1.1365, -0.5624, -0.5795, -0.4078, -0.6526,\n",
      "        -0.4954, -0.6838, -0.7479, -0.7356, -1.1823, -0.8910, -0.9698, -0.7208,\n",
      "        -0.7190, -0.8478, -1.1386, -0.9301, -0.8279, -0.9110, -0.5592, -0.8079,\n",
      "        -0.8850, -0.9068, -0.9947, -0.7778, -1.1016, -0.7793, -0.6256, -1.0822,\n",
      "        -1.0796, -0.9307, -0.6701, -0.7110, -1.1936, -0.9006, -0.7101, -1.1762,\n",
      "        -1.1048, -1.2214, -0.9222, -0.9778, -0.8330], grad_fn=<SelectBackward>)\n",
      "11\n",
      "[ 6 28 10 57 11 46 42  3 11]\n",
      "tensor([ 1.4536,  1.6224,  1.5963,  0.9620,  1.6443,  1.4073,  0.3718,  1.3552,\n",
      "         0.3634,  0.1207,  0.4296,  0.2938,  0.5189,  0.2392,  0.4648,  0.0620,\n",
      "         0.1050, -0.0472, -0.2278,  0.0243,  0.0963, -0.2901, -0.9397, -0.2702,\n",
      "        -0.7396, -0.8623, -0.8340, -0.5376, -0.9324, -0.6212, -0.7596, -0.8758,\n",
      "        -0.8663, -1.0124, -0.6652, -1.2292, -0.6239, -0.5872, -0.6014, -0.7926,\n",
      "        -0.6252, -0.7189, -1.0475, -0.9040, -1.3833, -0.9666, -1.0078, -0.7905,\n",
      "        -1.0495, -0.8830, -1.1156, -0.9940, -0.7805, -1.1901, -0.6712, -0.7349,\n",
      "        -1.0020, -1.0049, -0.8050, -0.6428, -1.1115, -0.9107, -0.8043, -1.1485,\n",
      "        -1.0317, -0.9103, -0.8905, -0.7552, -1.1986, -0.9524, -0.6884, -1.1683,\n",
      "        -1.0765, -1.2877, -0.9098, -0.9604, -0.9047], grad_fn=<SelectBackward>)\n",
      "15\n",
      "[ 6 28 10 57 11 46 42  3 11 15]\n",
      "tensor([ 1.6886,  2.0493,  1.7397,  1.3936,  1.5999,  1.1403,  0.4592,  1.0783,\n",
      "         0.4341,  0.1806,  0.5009,  0.4902,  0.6212,  0.0296,  0.2753,  0.1382,\n",
      "         0.1683, -0.0344, -0.2439, -0.0657,  0.2001, -0.4289, -0.8876, -0.1131,\n",
      "        -0.8987, -0.9223, -0.9936, -0.4146, -0.9312, -0.7031, -0.6477, -0.8601,\n",
      "        -0.9564, -1.1859, -0.6841, -1.0577, -0.5705, -0.7437, -0.5948, -0.9757,\n",
      "        -0.4680, -0.7161, -1.1842, -0.9204, -1.4199, -0.9136, -1.0983, -1.0861,\n",
      "        -1.3796, -0.9987, -1.2163, -0.8930, -0.9080, -1.4747, -0.7487, -0.8421,\n",
      "        -1.0727, -0.9225, -0.8066, -0.6316, -1.1389, -0.9850, -1.0848, -1.2313,\n",
      "        -1.0761, -1.0752, -0.9146, -0.8573, -1.4067, -1.0763, -0.6939, -1.2496,\n",
      "        -1.1231, -1.2969, -1.1701, -1.0399, -0.8778], grad_fn=<SelectBackward>)\n",
      "30\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30]\n",
      "tensor([ 1.3359,  1.7706,  1.8023,  1.2114,  1.6819,  1.2857,  0.6610,  0.9976,\n",
      "         0.5423,  0.1965,  0.4260,  0.4380,  0.4516,  0.0296,  0.3302,  0.2491,\n",
      "         0.4242,  0.0352, -0.1598, -0.0356,  0.2340, -0.3349, -0.7598, -0.1681,\n",
      "        -0.8185, -0.8756, -0.8298, -0.1849, -0.8954, -0.8020, -0.6528, -0.7246,\n",
      "        -0.8067, -0.8863, -0.7665, -1.0094, -0.5952, -0.6817, -0.6524, -0.8702,\n",
      "        -0.4033, -0.5320, -1.1342, -0.8706, -1.3510, -0.8616, -0.9425, -0.7031,\n",
      "        -1.0136, -0.9293, -1.2357, -0.7762, -0.8401, -1.2338, -0.6475, -0.7569,\n",
      "        -0.8428, -0.9804, -0.7650, -0.6752, -1.0417, -0.9040, -0.7403, -1.0648,\n",
      "        -0.9528, -0.8866, -0.8507, -0.7932, -1.2304, -0.9993, -0.6798, -1.2402,\n",
      "        -1.0839, -1.1950, -1.1161, -1.0473, -0.9540], grad_fn=<SelectBackward>)\n",
      "16\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16]\n",
      "tensor([ 1.4628,  1.8590,  2.0007,  1.4104,  1.5677,  1.1782,  0.6159,  0.8761,\n",
      "         0.5722,  0.1492,  0.1507,  0.5086,  0.3978,  0.2238,  0.2304,  0.1909,\n",
      "         0.3539, -0.0542, -0.0865,  0.0188,  0.1521, -0.2158, -0.7990, -0.0968,\n",
      "        -0.6579, -1.0539, -0.9635, -0.2808, -0.8455, -0.7542, -0.5991, -0.7214,\n",
      "        -0.7129, -1.0516, -0.7839, -0.8851, -0.5133, -0.8478, -0.5960, -0.8699,\n",
      "        -0.4526, -0.5366, -1.1047, -0.9544, -1.2841, -0.9444, -1.0715, -0.8093,\n",
      "        -0.9853, -0.9519, -1.3532, -0.6558, -0.6585, -1.3403, -0.6109, -0.7526,\n",
      "        -0.8584, -0.7441, -0.8001, -0.8634, -1.0457, -1.1343, -0.9904, -0.9956,\n",
      "        -0.9536, -0.7374, -0.7379, -0.7401, -1.2305, -0.9424, -0.5363, -1.1519,\n",
      "        -1.1189, -1.2276, -1.1537, -0.9905, -0.7824], grad_fn=<SelectBackward>)\n",
      "10\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10]\n",
      "tensor([ 1.6740,  2.0809,  2.1464,  1.7719,  2.0409,  1.5723,  0.6576,  1.2242,\n",
      "         0.9380,  0.2916,  0.3559,  0.6700,  0.4496,  0.2495,  0.3218,  0.3266,\n",
      "         0.4647, -0.0312, -0.1133, -0.0554,  0.1536, -0.3099, -0.8887, -0.0580,\n",
      "        -0.6520, -0.9981, -0.9647, -0.2263, -0.9443, -0.7394, -0.7160, -0.9251,\n",
      "        -0.7268, -1.0888, -0.7947, -1.1243, -0.4224, -0.8663, -0.5696, -0.9684,\n",
      "        -0.5602, -0.8283, -1.4427, -1.1278, -1.6337, -1.0267, -1.0503, -0.9023,\n",
      "        -0.9895, -0.9897, -1.4964, -0.8489, -0.7905, -1.3645, -0.6569, -0.8552,\n",
      "        -1.1177, -0.9482, -1.0141, -1.0343, -1.0554, -1.0987, -1.0368, -1.3020,\n",
      "        -1.0969, -0.8055, -0.6920, -0.8107, -1.4737, -1.1164, -0.6513, -1.2641,\n",
      "        -1.1883, -1.5284, -1.3009, -1.0842, -0.8992], grad_fn=<SelectBackward>)\n",
      "1\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1]\n",
      "tensor([ 1.9005,  1.9003,  2.1117,  2.1020,  1.9835,  2.0387,  0.5496,  1.3709,\n",
      "         1.1955,  0.3584,  1.0680,  0.6394,  0.5522,  0.3789,  0.4047,  0.4094,\n",
      "         0.5581,  0.1235, -0.1051, -0.2680,  0.0840, -0.2492, -0.9355, -0.1896,\n",
      "        -0.8290, -1.1899, -0.9295, -0.1494, -0.9708, -0.8177, -0.8767, -1.1304,\n",
      "        -0.9793, -1.2899, -0.9272, -1.3585, -0.6269, -1.0746, -0.7637, -1.0892,\n",
      "        -1.0220, -0.8312, -1.7096, -0.9810, -1.7742, -1.2199, -1.2004, -1.1257,\n",
      "        -1.0506, -1.3481, -1.6524, -1.1046, -0.9602, -1.4672, -0.7851, -1.0780,\n",
      "        -1.0880, -1.0758, -1.1424, -1.1974, -1.5931, -1.3967, -1.3650, -1.3181,\n",
      "        -1.2832, -1.1223, -1.0305, -1.0489, -1.7515, -1.2910, -1.0456, -1.4935,\n",
      "        -1.3511, -1.5996, -1.4124, -1.1754, -1.0562], grad_fn=<SelectBackward>)\n",
      "3\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3]\n",
      "tensor([ 2.0917,  1.9844,  2.1611,  1.7118,  2.3676,  2.3459,  0.3963,  1.8132,\n",
      "         0.8844,  0.0420,  0.8056,  0.5607,  0.5241,  0.4611,  0.5782,  0.3681,\n",
      "         0.4558, -0.0170, -0.1642, -0.1683,  0.0888, -0.3924, -1.2093, -0.3134,\n",
      "        -0.8107, -1.3066, -1.0925, -0.3365, -1.0868, -0.9068, -1.0072, -1.1832,\n",
      "        -1.2285, -1.3971, -1.0634, -1.5550, -0.6756, -1.0441, -0.6543, -1.0689,\n",
      "        -0.8014, -0.9127, -1.5796, -1.0847, -1.9116, -1.3818, -1.4121, -1.0831,\n",
      "        -1.0301, -1.2868, -1.7672, -1.2915, -1.1217, -1.5102, -0.8763, -1.0728,\n",
      "        -1.2272, -1.1767, -1.3246, -1.2640, -1.5658, -1.3696, -1.2552, -1.5338,\n",
      "        -1.3634, -1.2368, -1.0717, -0.9353, -1.7494, -1.4035, -0.9866, -1.7415,\n",
      "        -1.4565, -1.7074, -1.3792, -1.3716, -1.0388], grad_fn=<SelectBackward>)\n",
      "5\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5]\n",
      "tensor([ 1.5471,  2.4753,  2.5580,  1.7857,  2.2380,  1.8951,  0.4825,  1.4751,\n",
      "         0.9190,  0.0828,  0.6348,  0.6088,  0.6280,  0.6985,  0.5570,  0.4260,\n",
      "         0.8426,  0.0248, -0.2597, -0.1055,  0.3097, -0.0549, -0.9571, -0.1157,\n",
      "        -0.8166, -1.1358, -0.8983, -0.3367, -0.8373, -0.9098, -0.6437, -0.9981,\n",
      "        -1.0893, -1.0348, -0.9168, -1.1767, -0.4880, -0.9725, -0.6345, -1.0549,\n",
      "        -0.7552, -0.8323, -1.4039, -1.0018, -1.5668, -1.1478, -1.1377, -0.9670,\n",
      "        -1.1413, -1.1332, -1.4210, -1.0481, -0.9532, -1.4507, -0.8382, -0.8444,\n",
      "        -1.1531, -0.8965, -1.0975, -1.1280, -1.3518, -1.2045, -1.2561, -1.2993,\n",
      "        -1.1840, -1.0331, -1.0382, -0.6977, -1.6058, -1.2271, -0.8348, -1.4802,\n",
      "        -1.1549, -1.4631, -1.3228, -1.2137, -1.0981], grad_fn=<SelectBackward>)\n",
      "17\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17]\n",
      "tensor([ 1.3817,  2.0264,  2.3305,  1.7791,  2.0176,  1.6934,  0.3486,  1.4578,\n",
      "         0.9573,  0.1336,  0.5965,  0.5387,  0.5093,  0.6243,  0.5155,  0.3303,\n",
      "         0.7711,  0.1861, -0.2983, -0.1999,  0.2357, -0.0284, -0.7827, -0.0308,\n",
      "        -0.6302, -1.0229, -0.9874, -0.3736, -0.7709, -0.8582, -0.7310, -1.0124,\n",
      "        -0.8074, -1.0563, -0.8772, -1.2170, -0.4458, -0.8985, -0.5503, -0.9644,\n",
      "        -0.8476, -0.6633, -1.3817, -0.9267, -1.3673, -1.1180, -1.0859, -0.8100,\n",
      "        -0.9550, -0.8937, -1.3188, -1.0984, -0.7956, -1.3030, -0.7614, -0.8265,\n",
      "        -0.9059, -0.7519, -1.0804, -1.0024, -1.2583, -1.0078, -1.0614, -1.1307,\n",
      "        -0.8493, -0.7815, -1.0389, -0.7121, -1.2954, -1.1295, -0.6496, -1.1884,\n",
      "        -1.0072, -1.2774, -1.1327, -1.1513, -0.8909], grad_fn=<SelectBackward>)\n",
      "54\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54]\n",
      "tensor([ 1.6114,  2.0743,  2.2799,  1.8346,  1.7968,  1.4650,  0.4440,  1.3233,\n",
      "         0.9344,  0.2359,  0.5429,  0.5415,  0.5217,  0.3045,  0.4954,  0.3190,\n",
      "         0.5879,  0.0702, -0.1122, -0.0630,  0.2085, -0.1641, -0.8126, -0.1346,\n",
      "        -0.6790, -0.9960, -0.9904, -0.3100, -0.8357, -0.7496, -0.7929, -0.9673,\n",
      "        -0.7612, -1.1788, -0.8163, -1.1187, -0.5723, -0.8826, -0.6253, -1.0364,\n",
      "        -0.7753, -0.6621, -1.2518, -0.9643, -1.3763, -0.9893, -1.0757, -0.8118,\n",
      "        -1.0439, -0.8377, -1.4468, -0.9869, -0.8964, -1.2997, -0.6866, -0.8027,\n",
      "        -0.9409, -0.9569, -0.9541, -0.9390, -1.2886, -1.1536, -1.1590, -1.2171,\n",
      "        -0.8589, -1.0564, -0.9752, -0.7587, -1.5289, -1.2403, -0.7196, -1.2528,\n",
      "        -1.1455, -1.3833, -1.1734, -1.0931, -0.8846], grad_fn=<SelectBackward>)\n",
      "13\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13]\n",
      "tensor([ 1.5950,  2.0863,  2.1403,  1.6712,  2.3898,  1.5238,  0.4819,  1.5419,\n",
      "         0.9072,  0.0970,  0.8105,  0.5341,  0.5238,  0.2940,  0.5347,  0.4057,\n",
      "         0.6003,  0.0359, -0.1801, -0.0114,  0.2138, -0.1845, -0.7975, -0.1573,\n",
      "        -0.7173, -1.0874, -0.9696, -0.2365, -0.7997, -0.6534, -0.6541, -0.9595,\n",
      "        -0.8205, -1.0930, -0.9164, -1.1943, -0.6666, -0.7016, -0.4417, -0.9769,\n",
      "        -0.6819, -0.7056, -1.3318, -0.9223, -1.4439, -0.9159, -1.0377, -0.9699,\n",
      "        -0.9399, -0.9297, -1.3869, -1.0244, -0.8955, -1.3381, -0.7536, -1.0286,\n",
      "        -0.9525, -0.9538, -0.9589, -0.8527, -1.2348, -1.1079, -0.9792, -1.3582,\n",
      "        -1.0973, -1.2271, -1.1256, -0.9475, -1.5368, -1.1983, -0.9703, -1.2161,\n",
      "        -1.1413, -1.3040, -1.2210, -1.1073, -0.7961], grad_fn=<SelectBackward>)\n",
      "2\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2]\n",
      "tensor([ 1.5146,  2.7433,  2.2856,  2.0914,  2.4033,  1.8883,  0.7918,  1.8309,\n",
      "         0.6290,  0.2168,  0.8483,  0.4891,  0.8632,  0.5033,  0.4923,  0.4490,\n",
      "         0.5120, -0.0036, -0.2785,  0.0573,  0.0690, -0.2965, -1.1650, -0.0160,\n",
      "        -0.9257, -1.1827, -1.0159, -0.3284, -0.8235, -0.9889, -0.5232, -1.0189,\n",
      "        -0.9704, -1.1333, -0.7929, -1.5047, -0.5504, -0.9477, -0.5719, -1.0681,\n",
      "        -0.7751, -0.8715, -1.4993, -0.9967, -1.6706, -1.0125, -1.0562, -1.0685,\n",
      "        -1.0639, -1.1459, -1.6045, -0.9956, -0.9569, -1.5106, -0.8504, -1.1050,\n",
      "        -1.1396, -1.1885, -1.3280, -1.0998, -1.4045, -1.2636, -1.2913, -1.3169,\n",
      "        -1.2154, -1.3041, -1.2616, -1.2219, -1.5734, -1.2965, -1.0509, -1.4902,\n",
      "        -1.2802, -1.3257, -1.5667, -1.3245, -1.0304], grad_fn=<SelectBackward>)\n",
      "1\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1]\n",
      "tensor([ 1.7569,  2.2950,  2.2208,  2.2140,  2.2420,  2.2343,  0.6463,  1.6544,\n",
      "         1.1087,  0.2686,  1.3037,  0.6744,  0.7188,  0.5516,  0.5739,  0.5216,\n",
      "         0.6473,  0.0897, -0.1416, -0.1855,  0.0343, -0.2220, -0.9896, -0.1423,\n",
      "        -0.9189, -1.3285, -0.8857, -0.1699, -0.8799, -0.7916, -0.7997, -1.1259,\n",
      "        -1.0728, -1.2787, -0.8638, -1.6051, -0.6619, -1.0502, -0.7540, -1.0493,\n",
      "        -1.1049, -0.8796, -1.7492, -0.9215, -1.7474, -1.1745, -1.1893, -1.1078,\n",
      "        -1.0518, -1.3251, -1.6707, -1.1776, -1.0430, -1.5370, -0.8435, -1.1315,\n",
      "        -1.0816, -1.1746, -1.1589, -1.1671, -1.6900, -1.4596, -1.4872, -1.3751,\n",
      "        -1.2549, -1.2913, -1.2486, -1.2352, -1.7499, -1.3431, -1.2020, -1.5468,\n",
      "        -1.3054, -1.4975, -1.4888, -1.2886, -1.1330], grad_fn=<SelectBackward>)\n",
      "3\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3]\n",
      "tensor([ 1.8994,  2.2816,  2.2688,  1.8036,  2.4628,  2.4611,  0.4920,  1.9602,\n",
      "         0.9014,  0.0360,  0.9906,  0.6107,  0.6873,  0.5591,  0.6705,  0.5242,\n",
      "         0.5435, -0.0147, -0.1739, -0.1148,  0.1152, -0.3457, -1.2022, -0.2091,\n",
      "        -0.9108, -1.3549, -1.0770, -0.3428, -1.0348, -0.8526, -0.9018, -1.1727,\n",
      "        -1.2629, -1.3651, -0.9859, -1.7138, -0.6829, -1.0252, -0.6060, -1.0505,\n",
      "        -0.8505, -0.9034, -1.5853, -1.0193, -1.8418, -1.3907, -1.4173, -1.0730,\n",
      "        -1.0535, -1.2735, -1.7586, -1.2982, -1.1313, -1.5785, -0.9133, -1.0649,\n",
      "        -1.1421, -1.2861, -1.2826, -1.1737, -1.5986, -1.3758, -1.3522, -1.5559,\n",
      "        -1.2964, -1.3327, -1.1659, -1.0684, -1.6968, -1.4554, -1.0358, -1.6685,\n",
      "        -1.3606, -1.5802, -1.3868, -1.3871, -1.0743], grad_fn=<SelectBackward>)\n",
      "22\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22]\n",
      "tensor([ 1.4638,  1.9331,  2.2858,  1.5325,  1.7329,  1.8144,  0.7278,  1.4194,\n",
      "         0.9325,  0.7787,  0.5387,  0.4413,  0.5909,  0.5138,  0.4471,  0.5567,\n",
      "         0.5481, -0.0399, -0.1958, -0.1116,  0.3322, -0.1483, -0.8887, -0.1191,\n",
      "        -0.6095, -0.9161, -0.9648, -0.6041, -0.8952, -0.8140, -0.8421, -1.0043,\n",
      "        -0.9071, -1.1291, -0.8831, -1.3942, -0.5444, -0.8415, -0.5302, -0.9565,\n",
      "        -0.8366, -0.6686, -1.1731, -1.0669, -1.6334, -1.0173, -1.0809, -0.7968,\n",
      "        -0.8052, -0.9407, -1.4684, -1.0485, -0.9961, -1.5027, -0.7686, -0.9796,\n",
      "        -1.1129, -1.0939, -1.1292, -1.0386, -1.3212, -1.0276, -1.1577, -1.2422,\n",
      "        -1.0349, -1.0080, -1.0423, -1.0407, -1.3704, -1.3449, -0.8145, -1.3314,\n",
      "        -1.1433, -1.3392, -1.0733, -1.0296, -0.9927], grad_fn=<SelectBackward>)\n",
      "65\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65]\n",
      "tensor([ 1.9000,  2.1415,  2.1255,  1.6414,  2.0470,  1.7411,  0.7189,  1.3900,\n",
      "         0.7766,  0.4319,  0.4405,  0.4162,  0.6283,  0.3612,  0.6245,  0.3586,\n",
      "         0.3625, -0.0745, -0.2360, -0.2122,  0.0738, -0.2701, -1.0254, -0.1749,\n",
      "        -0.8690, -1.1505, -1.0700, -0.5285, -1.0564, -0.7409, -0.8864, -0.9507,\n",
      "        -0.9899, -1.1453, -0.7986, -1.3656, -0.5664, -0.9186, -0.6493, -0.8966,\n",
      "        -0.7332, -0.7213, -1.4172, -0.8854, -1.7424, -1.1315, -1.1166, -0.8344,\n",
      "        -1.0325, -1.0289, -1.5976, -1.1815, -0.9847, -1.6098, -0.7112, -0.9580,\n",
      "        -1.1936, -1.1730, -1.1997, -1.2142, -1.3765, -1.1123, -1.2940, -1.3812,\n",
      "        -1.1323, -1.1268, -1.1562, -1.1220, -1.6508, -1.3964, -0.9095, -1.3585,\n",
      "        -1.4462, -1.4689, -1.2033, -1.0917, -1.0713], grad_fn=<SelectBackward>)\n",
      "7\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7]\n",
      "tensor([ 1.1478,  2.2301,  2.3886,  1.5644,  1.8244,  2.1435,  0.8777,  1.4737,\n",
      "         1.1000,  0.4854,  0.7734,  0.7620,  0.5901,  0.4706,  0.6857,  0.8495,\n",
      "         0.4648,  0.1180, -0.1142,  0.0712,  0.5345, -0.0680, -0.9027,  0.0663,\n",
      "        -0.6507, -0.9588, -0.7415, -0.3886, -0.7605, -0.6804, -0.6007, -0.7600,\n",
      "        -0.9318, -1.0848, -0.7188, -1.3994, -0.4816, -0.6985, -0.5120, -0.9077,\n",
      "        -0.6247, -0.7778, -1.2526, -0.8247, -1.5166, -0.9709, -1.0600, -0.8244,\n",
      "        -0.9158, -0.9915, -1.5429, -0.9838, -0.9721, -1.4289, -0.5160, -0.7796,\n",
      "        -0.9824, -1.1574, -1.1549, -0.9563, -1.2247, -1.1273, -1.2726, -1.3555,\n",
      "        -0.9851, -0.8808, -1.0953, -0.9962, -1.3488, -1.2751, -0.8291, -1.3831,\n",
      "        -1.2859, -1.3048, -1.1707, -1.1727, -1.0859], grad_fn=<SelectBackward>)\n",
      "1\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1]\n",
      "tensor([ 1.5066,  2.0794,  2.2512,  2.0023,  1.9089,  2.2799,  0.6925,  1.4758,\n",
      "         1.2579,  0.4829,  1.2559,  0.7862,  0.6006,  0.5216,  0.6172,  0.6924,\n",
      "         0.6149,  0.1366, -0.1020, -0.1957,  0.2608, -0.0825, -0.8728, -0.0655,\n",
      "        -0.8357, -1.1693, -0.7525, -0.1837, -0.8787, -0.6694, -0.8468, -0.9181,\n",
      "        -0.9570, -1.2614, -0.8358, -1.5278, -0.5785, -0.9649, -0.7189, -0.9780,\n",
      "        -1.0402, -0.8697, -1.5742, -0.7611, -1.6679, -1.1575, -1.1818, -1.0776,\n",
      "        -1.0204, -1.2447, -1.6715, -1.1333, -1.0605, -1.4731, -0.6622, -1.0555,\n",
      "        -1.0467, -1.1347, -1.0490, -1.1234, -1.6307, -1.3658, -1.4953, -1.3079,\n",
      "        -1.1670, -1.1341, -1.1527, -1.1175, -1.6911, -1.2941, -1.0771, -1.4792,\n",
      "        -1.2934, -1.4830, -1.3240, -1.2043, -1.1455], grad_fn=<SelectBackward>)\n",
      "1\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1]\n",
      "tensor([ 1.6568,  2.0453,  2.2207,  2.1615,  1.9569,  2.3325,  0.6116,  1.5367,\n",
      "         1.3924,  0.4222,  1.4146,  0.7560,  0.6504,  0.5385,  0.6094,  0.6412,\n",
      "         0.6806,  0.1354, -0.0919, -0.2827,  0.1849, -0.1475, -0.8876, -0.1022,\n",
      "        -0.8806, -1.2534, -0.8194, -0.1622, -0.8855, -0.7056, -0.8807, -1.0951,\n",
      "        -0.9560, -1.2921, -0.9362, -1.5231, -0.6545, -1.0562, -0.7523, -1.0263,\n",
      "        -1.1719, -0.9123, -1.6996, -0.7977, -1.7284, -1.1965, -1.2330, -1.1528,\n",
      "        -1.0723, -1.3269, -1.6867, -1.2226, -1.1270, -1.4549, -0.7552, -1.0937,\n",
      "        -1.0155, -1.1123, -1.0753, -1.1362, -1.7647, -1.3976, -1.5573, -1.3266,\n",
      "        -1.2026, -1.2281, -1.1613, -1.1435, -1.7419, -1.3526, -1.1532, -1.4760,\n",
      "        -1.3492, -1.5253, -1.3736, -1.2372, -1.1492], grad_fn=<SelectBackward>)\n",
      "5\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5]\n",
      "tensor([ 1.2044,  2.4660,  2.5601,  1.9918,  2.0527,  1.8827,  0.5888,  1.4373,\n",
      "         1.1977,  0.2461,  0.8349,  0.7140,  0.7329,  0.7109,  0.5559,  0.5748,\n",
      "         0.9396,  0.1576, -0.2343, -0.0668,  0.3817,  0.0963, -0.7751,  0.0329,\n",
      "        -0.7374, -1.0571, -0.8939, -0.2137, -0.6653, -0.8543, -0.5785, -0.9797,\n",
      "        -0.8595, -0.9278, -0.8973, -1.0789, -0.5419, -0.8834, -0.6003, -1.0110,\n",
      "        -0.8564, -0.8064, -1.4306, -0.8303, -1.4299, -1.0142, -1.0670, -0.9714,\n",
      "        -1.0939, -1.0462, -1.3142, -0.9762, -0.8863, -1.2480, -0.7578, -0.8467,\n",
      "        -0.9356, -0.7956, -1.0140, -1.0274, -1.2754, -1.1646, -1.3151, -1.0978,\n",
      "        -1.0181, -0.9737, -0.9646, -0.7644, -1.5425, -1.2225, -0.8724, -1.2713,\n",
      "        -1.0562, -1.3005, -1.2594, -1.1535, -1.0520], grad_fn=<SelectBackward>)\n",
      "12\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12]\n",
      "tensor([ 0.8967,  2.6398,  2.4107,  1.9534,  1.9636,  2.0161,  0.6913,  1.5200,\n",
      "         1.0472,  0.3109,  0.8010,  0.6923,  0.8020,  0.3729,  0.5237,  0.4788,\n",
      "         0.6920,  0.1346, -0.2377,  0.0420,  0.3402,  0.1738, -0.5680,  0.1120,\n",
      "        -0.7138, -0.9764, -0.8648, -0.1009, -0.6523, -0.8791, -0.4644, -0.9572,\n",
      "        -0.6279, -0.9128, -0.8940, -1.0210, -0.4938, -0.7438, -0.3231, -0.7832,\n",
      "        -0.7413, -0.7905, -1.1206, -0.8798, -1.3147, -0.8607, -0.8995, -0.7497,\n",
      "        -0.7545, -0.9357, -1.3346, -1.0808, -0.7208, -1.1439, -0.5047, -0.8574,\n",
      "        -0.8070, -0.7243, -0.8980, -1.0254, -1.1696, -0.9321, -1.1498, -1.0503,\n",
      "        -0.8911, -0.9063, -1.0465, -0.8170, -1.3245, -1.2504, -0.7274, -1.1435,\n",
      "        -1.0951, -1.2820, -1.2505, -1.1188, -0.9924], grad_fn=<SelectBackward>)\n",
      "40\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40]\n",
      "tensor([ 1.0626,  2.0348,  2.2775,  1.7903,  1.6286,  1.4858,  0.7576,  1.2312,\n",
      "         0.8551,  0.4750,  0.6081,  0.6273,  0.3727,  0.2231,  0.3310,  0.5526,\n",
      "         0.5543,  0.0690, -0.1037, -0.0285,  0.2606,  0.0449, -0.6603, -0.0227,\n",
      "        -0.5848, -0.9265, -0.6790, -0.0601, -0.6778, -0.7232, -0.4843, -0.8467,\n",
      "        -0.6260, -0.9035, -0.6554, -1.0660, -0.2971, -0.6558, -0.6394, -0.8365,\n",
      "        -0.5443, -0.6729, -1.0435, -0.7107, -1.2780, -0.8833, -1.0418, -0.7993,\n",
      "        -0.7870, -1.0310, -1.3476, -0.9881, -0.4720, -1.0793, -0.5008, -0.8504,\n",
      "        -0.8758, -0.9531, -0.9975, -0.9026, -1.1690, -1.0197, -1.2979, -1.0474,\n",
      "        -0.8287, -0.7569, -0.9624, -0.8960, -1.2460, -1.3239, -0.7642, -1.1714,\n",
      "        -0.9971, -1.1998, -1.1590, -1.0150, -0.8780], grad_fn=<SelectBackward>)\n",
      "27\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40 27]\n",
      "tensor([ 1.4233,  1.9333,  2.2805,  1.5244,  1.6417,  1.4275,  0.7181,  1.2768,\n",
      "         0.8396,  0.3851,  0.6569,  0.5022,  0.3193,  0.0742,  0.3350,  0.3988,\n",
      "         0.4518, -0.0812, -0.1623, -0.0627,  0.2358, -0.0609, -0.6986, -0.2070,\n",
      "        -0.7859, -1.0376, -0.6970, -0.1218, -0.9124, -0.6794, -0.6600, -1.0123,\n",
      "        -0.7163, -0.9484, -0.8878, -1.1009, -0.4748, -0.9377, -0.7022, -0.9935,\n",
      "        -0.8251, -0.8989, -1.1711, -1.0163, -1.4975, -1.1926, -1.2461, -0.9386,\n",
      "        -0.9513, -1.1298, -1.4405, -1.1241, -0.7395, -1.3192, -0.6891, -1.0730,\n",
      "        -0.8834, -1.0091, -1.1748, -0.9605, -1.3154, -1.1467, -1.1097, -1.2750,\n",
      "        -0.9988, -0.7192, -0.8783, -0.9068, -1.1960, -1.3088, -0.8761, -1.2682,\n",
      "        -1.1389, -1.3443, -1.1707, -1.0611, -1.1783], grad_fn=<SelectBackward>)\n",
      "68\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40 27 68]\n",
      "tensor([ 1.4350e+00,  1.8023e+00,  1.9906e+00,  1.4494e+00,  1.5349e+00,\n",
      "         1.4475e+00,  6.0781e-01,  1.1718e+00,  7.8227e-01,  4.0580e-01,\n",
      "         5.6110e-01,  6.7837e-01,  2.6102e-01,  2.3009e-01,  2.8709e-01,\n",
      "         4.5217e-01,  4.0177e-01, -1.3609e-02, -3.3080e-01, -1.1360e-01,\n",
      "         2.2937e-01, -1.3925e-01, -6.3881e-01,  7.6037e-04, -6.4323e-01,\n",
      "        -9.9833e-01, -7.7358e-01, -1.0988e-01, -8.4166e-01, -7.7946e-01,\n",
      "        -6.5575e-01, -9.8101e-01, -6.5212e-01, -9.4816e-01, -8.3258e-01,\n",
      "        -1.1018e+00, -4.6674e-01, -9.9313e-01, -7.2034e-01, -1.0562e+00,\n",
      "        -6.3411e-01, -5.5830e-01, -1.2463e+00, -8.4524e-01, -1.3593e+00,\n",
      "        -1.2067e+00, -1.1860e+00, -8.0386e-01, -8.9345e-01, -9.2426e-01,\n",
      "        -1.3887e+00, -1.0440e+00, -6.4710e-01, -1.2909e+00, -5.8585e-01,\n",
      "        -9.7972e-01, -8.5177e-01, -9.9372e-01, -1.1602e+00, -9.1688e-01,\n",
      "        -1.1053e+00, -1.0840e+00, -1.0046e+00, -1.1651e+00, -8.8212e-01,\n",
      "        -8.2703e-01, -9.5354e-01, -6.7930e-01, -1.0926e+00, -1.3089e+00,\n",
      "        -6.3680e-01, -1.1590e+00, -9.1564e-01, -1.2471e+00, -1.1537e+00,\n",
      "        -9.1486e-01, -1.1473e+00], grad_fn=<SelectBackward>)\n",
      "53\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40 27 68 53]\n",
      "tensor([ 1.2701,  1.6255,  1.9378,  1.2996,  1.4540,  1.2640,  0.4835,  1.0838,\n",
      "         0.8088,  0.2450,  0.5299,  0.6059,  0.2857,  0.3306,  0.3303,  0.1802,\n",
      "         0.4244, -0.0794, -0.1819, -0.0904,  0.1566, -0.1028, -0.8159, -0.0980,\n",
      "        -0.7442, -1.0348, -0.7698, -0.2384, -0.9023, -0.6823, -0.7492, -0.7523,\n",
      "        -0.5457, -0.9231, -0.7456, -1.0144, -0.4696, -0.9492, -0.7199, -0.9537,\n",
      "        -0.7628, -0.7854, -1.0063, -1.0958, -1.1907, -1.0955, -1.0820, -0.8282,\n",
      "        -0.9875, -0.9048, -1.3259, -0.9590, -0.8460, -1.2966, -0.7794, -1.0343,\n",
      "        -0.8673, -0.8764, -1.0122, -0.7813, -1.2149, -1.0297, -0.9251, -1.1775,\n",
      "        -0.8819, -0.9418, -0.6981, -0.7179, -0.9024, -1.0916, -0.5807, -1.2328,\n",
      "        -0.9753, -1.2857, -1.2113, -0.8542, -1.1148], grad_fn=<SelectBackward>)\n",
      "0\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40 27 68 53  0]\n",
      "[ 6 28 10 57 11 46 42  3 11 15 30 16 10  1  3  5 17 54 13  2  1  3 22 65\n",
      "  7  1  1  5 12 40 27 68 53  0]\n",
      "['| 5 c ~ i W B a i d 6 h c   a t m z u e   a & = n     t s v w q']\n"
     ]
    }
   ],
   "source": [
    "def predict(dm, model, seed_text=None, max_length=None):\n",
    "    model.eval()\n",
    "    \n",
    "    if seed_text:\n",
    "        sequence = np.array(dm.tok.texts_to_sequences(seed_text))\n",
    "    else:\n",
    "        #If we want pure generation, need to just seed the startingin field post\n",
    "        sequence = np.array(dm.tok.texts_to_sequences('|'))\n",
    "        print(sequence)\n",
    "    \n",
    "    state_h, _ = model.init_state(len(sequence))\n",
    "    \n",
    "    if max_length:\n",
    "        print(max_length)\n",
    "        for i in range(max_length):\n",
    "            \n",
    "            x = torch.from_numpy(sequence).to(torch.int64)\n",
    "            y_pred = model(x.view(1,-1))\n",
    "            p = torch.nn.functional.softmax(y_pred[0][-1], dim=0).detach().numpy()\n",
    "            char_index = np.random.choice(len(y_pred[0][-1]), p=p)\n",
    "            sequence = np.append(sequence, char_index)\n",
    "            \n",
    "    else:\n",
    "        while sequence[-1] != 0:\n",
    "            x = torch.from_numpy(sequence).to(torch.int64)\n",
    "            y_pred = model(x.view(1,-1))\n",
    "\n",
    "            last_word_logits = y_pred[0][-1]\n",
    "            p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "            char_index = np.random.choice(len(y_pred[0][-1]), p=p)\n",
    "            sequence = np.append(sequence, char_index)\n",
    "\n",
    "    \n",
    "    print(sequence)\n",
    "    output = dm.tok.sequences_to_texts(sequence.reshape(1,-1))\n",
    "    \n",
    "    return output\n",
    "\n",
    "sampler = RNN.load_from_checkpoint(\"logs/rnn/version_97/checkpoints/epoch=4.ckpt\",\n",
    "                                   hparams_file=\"logs/rnn/version_97/hparams.yaml\")\n",
    "\n",
    "sample = predict(magic_cards_dm, sampler, seed_text=\"|5c\")\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
